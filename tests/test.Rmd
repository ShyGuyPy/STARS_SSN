---
title: "test"
author: "Luke Vawter"
date: "3/2/2022"
output: html_document
---

# -Introduction-

This is a modification of STARS_SSN_V2(which ran to completion but gave bad output).
This is the first version to run to completion and give full outputs, including predictions.This should be the template for ssn runs moving forward.


There is sample code for running an SSN prediction model at:

https://www.fs.fed.us/rm/boise/AWAE/projects/NorWeST/downloads/NorWeST%20SSN%20example%20code.R

When sample code is referenced here, this is what is being referred to

# -Initial Set-up-

### Install Packages and Set Data Path

the SSN library is imported. A path for our the SSN data is set. This data is an output from Andrea Nagel's run of STARS.
```{r}
library(SSN)
library(dplyr)
library(lubridate)

 data_path ='data/ICPRB4/lsn.ssn'
```

### Create Custom Functions

functions are created for standardizing variables and predictions, that will be used later. These have been pulled directly from the sample code.
```{r}
# Function to standardize variables
stand <- function(x) { (x-mean(x))/(2*sd(x))}

# Function to standardize a prediction dataset based on the fitting dataset 
stdpreds <- function(newset,originalset) {
	xnames <- colnames(newset)
	sx <- matrix(rep(NA,ncol(newset)*nrow(newset)),nrow=nrow(newset))
	for(i in 1:ncol(newset)) {
		var <- with(originalset,get(xnames[i]))
		sx[,i] <- (newset[,i]-mean(var))/(2*sd(var))
		}
	colnames(sx) <- colnames(newset)
	return(sx)
}
```

### Import Data to SSN Object

import the data from our data to an ssn object
```{r}

test.ssn <- importSSN(data_path, predpts = "preds", o.write = T)
```

### Clean Data

from our ssn object we grab a dataframe and push the dataframe back into he ssn object. We also convert DATE value to julian. 
We also remove two covariates (AREAKM2 and TOTDAKM2) that were causing the glmssn function to fail
```{r}
test_temp.df<- getSSNdata.frame(test.ssn) 

test_temp.df<- select(test_temp.df, -AREAKM2, -TOTDAKM2)

test_temp.df <- test_temp.df %>%
  mutate(DATE_ = as.Date(test_temp.df$DATE_, "%Y-%m-%d")) %>%
  mutate(DATE_ =  yday(test_temp.df$DATE_))

test.ssn <- putSSNdata.frame(test_temp.df,test.ssn,"Obs")
test_temp.df<- getSSNdata.frame(test.ssn) 
```

Save the ssn dataframe to our data folder for reference
```{r}
# write.csv(test.ssn,"data/ICPRB4/test_ssn.csv")
```

# -Run-

### Distance Matrix

createDistMat function creates a distance matrix. Memory limits for R needed to be increased to run. I set it to 200000 MB, and that was sufficient for our data. Predpts are named preds in our lsn.ssn file and so are given the value 'preds'.
```{r}
#had to check memory and then adjust memory limit
memory.size()
memory.limit()
memory.limit(size=200000)

#dist_mat_test = 
createDistMat(test.ssn, o.write=T, predpts = 'preds', amongpreds=T)
# ssn, predpts = NULL, o.write = FALSE, amongpreds = FALSE)
```
### Torgegrams

create Torgegram
```{r}
# Create raw torgegram
test_torg <- Torgegram(test.ssn,"TWAT",nlag=20)
plot(test_torg)

```

plot Torgegram for connected and unconnected(should be dipslayed in kilometers)and save both as jpegs
```{r}
jpeg("data/ICPRB4/torgegram_flow_connected.jpg")
plot.Torgegram(test_torg, sp.relationship = c("fc"), xlab = "Stream Distance (meter)")
dev.off()

plot.Torgegram(test_torg, sp.relationship = c("fc"), xlab = "Stream Distance (meter)")

jpeg("data/ICPRB4/torgegram_flow_unconnected.jpg")
plot.Torgegram(test_torg, sp.relationship = c("fu"), xlab = "Stream Distance (meter)")
dev.off()

plot.Torgegram(test_torg, sp.relationship = c("fu"), xlab = "Stream Distance (meter)")
```

Extract dataframe and fit basic aspatial model with un-standardized predictors
```{r}
test.df<- getSSNdata.frame(test.ssn)

test.lm <- lm(TWAT ~ TAIR + PRECIP + SOLRAD + FLOW + ELEV + SLOPE + PURB16 + PFOR16 + PAG16 + PWSTOR16 + PCAN14 + PIMP14 + PEWET + PFWET + PRWET + PHYDA, data=test.df)
summary(test.lm)
```

### Standardize Covariates

Standardize continuous covariates and add factor for year
The following steps are taken from sample code and adapted to fit our data indices/covariates
```{r}
# Standardize continuous covariates and add factor for year
continuous <- test.df[,c(13:28)] #[,c(14:29)]
cont.s <- apply(continuous,2,stand)
colnames(cont.s) <- c("TAIR","PRECIP","SOLRAD","FLOW","ELEV","SLOPE","PURB16","PFOR16","PAG16", "PWSTOR16", "PCAN14", "PIMP14", "PEWET", "PFWET", "PRWET", "PHYDA") 

test.df.s <- data.frame(test.df,cont.s)

test.df.s$datef <- factor(test.df.s$DATE_)

test_master <- putSSNdata.frame(test.df.s,test.ssn,"Obs")
```

esttable is constructed and saved
```{r}
library(tibble)
testAe <- summary(test.lm)$coefficients

backtrans <- testAe[-c(1),1:2]/(2*sapply(continuous,sd))

esttable <- cbind(rbind(testAe[1,1:2],backtrans[1:15,],testAe[10,1:2]),testAe)

#fixes row names by overwriting them
rownames(esttable) <- rownames(testAe)

write.csv(esttable,"data/ICPRB4/test_aspatialestimates.csv")

# # Aspatial performance
predictA <- predict(test.lm)
sqrt(mean((predictA-test.df.s$TWAT)^2))
# # print(predictA)
# # 1.885
```

```{r}
# Examine correlations
library(ellipse)
library(corrplot)

#color for legend
COL1(sequential = c("Oranges", "Purples", "Reds", "Blues", "Greens",
                    "Greys", "OrRd", "YlOrRd", "YlOrBr", "YlGn"), n = 200)

cor1 = cor(cont.s)
jpeg("data/ICPRB4/corrplot.jpg")
corrplot(cor1, type='lower',col=COL1())
# plotcorr(cor(cont.s), col=COL1,type="lower")
dev.off()

#NOTE: call the legend for this output
```