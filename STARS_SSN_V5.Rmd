---
title: "STARS_SSN_V5"
author: "Luke Vawter"
date: "2/25/2022"
output: html_document
---

---
title: "STARS_SSN"
output: html_document
---

there is sample code for running an SSN prediction model at:

https://www.fs.fed.us/rm/boise/AWAE/projects/NorWeST/downloads/NorWeST%20SSN%20example%20code.R

When sample code is referenced here, this is what is being referred to


the SSN library is imported. A path for our the SSN data is set. This data is an output from Andrea Nagel's run of STARS.
```{r}
library(SSN)
library(dplyr)
library(lubridate)

 data_path ='data/ICPRB5/lsn.ssn'
 
```

functions are created for standardizing variables and predictions, that will be used later. These have been pulled directly from the sample code.
```{r}
# Function to standardize variables
stand <- function(x) { (x-mean(x))/(2*sd(x))}

# Function to standardize a prediction dataset based on the fitting dataset 
stdpreds <- function(newset,originalset) {
	xnames <- colnames(newset)
	sx <- matrix(rep(NA,ncol(newset)*nrow(newset)),nrow=nrow(newset))
	for(i in 1:ncol(newset)) {
		var <- with(originalset,get(xnames[i]))
		sx[,i] <- (newset[,i]-mean(var))/(2*sd(var))
		}
	colnames(sx) <- colnames(newset)
	return(sx)
}
```

import our data to an ssn object
```{r}

test.ssn <- importSSN(data_path, predpts = "preds", o.write = T)
```

from our ssn object we grab a dataframe, convert DATE variable to julian, and push the dataframe back into the ssn object.  


```{r}
test_temp.df<- getSSNdata.frame(test.ssn) 

test_temp.df <- test_temp.df %>%
  mutate(DATE_ = as.Date(test_temp.df$DATE_, "%Y-%m-%d")) %>%
  mutate(DATE_ =  yday(test_temp.df$DATE_))

test.ssn <- putSSNdata.frame(test_temp.df,test.ssn,"Obs")
test_temp.df<- getSSNdata.frame(test.ssn) 
```

Save the ssn dataframe to our data folder for reference
```{r}
write.csv(test.ssn,"data/ICPRB5/test_ssn.csv")
```

createDistMat function creates a distance matrix. Memory limits for R needed to be increased to run. I set it to 200000 MB, and that was sufficient for our data. Predpts are named preds in our lsn.ssn file and so are given the value 'preds'.
```{r}
#incerease memory limit
memory.size()
memory.limit()
memory.limit(size=200000)

#create a distance matrix
createDistMat(test.ssn, o.write=T, predpts = 'preds', amongpreds=T)

```

a Torgegram is created from the ssn object
```{r}
# Create raw torgegram
test_torg <- Torgegram(test.ssn,"TWAT",nlag=20)

```

plot Torgegram for connected and unconnected and save both as jpegs
```{r}
jpeg("data/ICPRB5/torgegram_flow_connected.jpg")
plot.Torgegram(test_torg, sp.relationship = c("fc"), xlab = "Stream Distance (meter)")
dev.off()

jpeg("data/ICPRB5/torgegram_flow_unconnected.jpg")
plot.Torgegram(test_torg, sp.relationship = c("fu"), xlab = "Stream Distance (meter)")
dev.off()
```

Extract dataframe and fit basic spatial model with un-standardized predictors

```{r}
test.df<- getSSNdata.frame(test.ssn)

test.lm <- lm(TWAT ~ TAIR + PRECIP + SOLRAD +  ELEV + SLOPE + PURB16 + PFOR16 + PAG16 + PWSTOR16 + PCAN14 + PIMP14 + PEWET + PFWET + PRWET + PHYDA + AREAKM2 +TOTDAKM2 + SSO + BFI + WSHED, 
data=test.df)
summary(test.lm)
```

# Standardize continuous covariates and add factor for year
The following steps are taken from sample code and adapted to fit our data indices/covariates
```{r}
# Standardize continuous covariates and add factor for year
continuous <- test.df[,c(13:32)]
cont.s <- apply(continuous,2,stand)
colnames(cont.s) <- c("TAIR","PRECIP","SOLRAD","ELEV","SLOPE","PURB16","PFOR16","PAG16", "PWSTOR16", "PCAN14", "PIMP14","PEWET", "PFWET", "PRWET", "PHYDA", "AREAKM2", "TOTDAKM2", "SSO", "BFI", "WSHED")
test.df.s <- data.frame(test.df,cont.s)

test.df.s$datef <- factor(test.df.s$DATE_)

test_master <- putSSNdata.frame(test.df.s,test.ssn,"Obs")
```

estimate table(esttable) is saved

note: the summary function can sometimes dropped covariates if they include NA or -9999 values 
```{r}
library(tibble)
testAe <- summary(test.lm)$coefficients

backtrans <- testAe[-c(1),1:2]/(2*sapply(continuous,sd))

esttable <- cbind(rbind(testAe[1,1:2], backtrans[1:18,],testAe[10,1:2]),testAe)

#fixes row names by overwriting them
rownames(esttable) <- rownames(testAe)

write.csv(esttable,"data/ICPRB5/test_aspatialestimates.csv")

# # Aspatial performance
predictA <- predict(test.lm)
sqrt(mean((predictA-test.df.s$TWAT)^2))
```

# Examine correlations
Generate a correlation plot and save it to data folder
```{r}
library(ellipse)
library(corrplot)

#color for legend
COL1(sequential = c("Oranges", "Purples", "Reds", "Blues", "Greens",
                    "Greys", "OrRd", "YlOrRd", "YlOrBr", "YlGn"), n = 200)

# generate correlation plot and save
cor1 = cor(cont.s)
jpeg("data/ICPRB5/corrplot.jpg")
corrplot(cor1, type='lower',col=COL1())
dev.off()

```

# Standardize preds based on obs and add factor for year- pred
Code is adapted from sample code to fit our data indices/covariates and output is saved 
```{r}
testpreddf <- getSSNdata.frame(test.ssn, "preds")


contpred <- testpreddf[,c(13:32)]
contpred.s <- stdpreds(contpred,continuous)

 colnames(contpred.s) <-
c("TAIR", "PRECIP", "SOLRAD", "ELEV", "SLOPE", "PURB16", "PFOR16", "PAG16", "PWSTOR16", "PCAN14", "PIMP14", "PEWET", "PWFET", "PRWET", "PHYDA", "AREAKM2","TOTDAKM2", "SSO", "BFI", "WSHED")
testpreddf.s <- data.frame(testpreddf,contpred.s)
testpreddf.s$datef <- factor(testpreddf.s$DATE_)
test_master <- putSSNdata.frame(testpreddf.s,test_master,"preds")

testmaster <- getSSNdata.frame(test_master, "preds")
write.csv(testmaster,"data/ICPRB5/testmaster.csv")
```

### -Model # 1- ###

"The glmssn function fits a spatial linear model (Equation 3) to a SpatialStreamNetwork
object with a covariance structure"

The glmssn function can take hours to run. 

"This limits the size of data sets that can be fit by the glmssn
function, and for most computing systems today we suggest sample sizes of less than 1000 observations."
https://www.fs.fed.us/rm/boise/AWAE/projects/SSN_STARS/downloads/SSN/SSNvignette2014.pdf
page21

Also, we track glmssn run time(elapsed variable), as recommended by sample code

```{r}

starttime <- Sys.time() # not necessary; just for timing longer runs
test_1 <- glmssn(formula = TWAT ~ TAIR + PRECIP + SOLRAD + ELEV + SLOPE + PURB16 + PFOR16 + PAG16 + PWSTOR16 + PCAN14 + PIMP14, + PEWET + PFWET + PRWET + PHYDA + AREAKM2 + TOTDAKM2 + SSO + BFI + WSHED, 
                 ssn.object = test_master, EstMeth= "ML", family="gaussian", CorModels = c("locID","datef","Exponential.tailup","Exponential.taildown","Exponential.Euclid"), addfunccol = "afvArea")

elapsed <- Sys.time()-starttime # See above note
```

# Extract predictions/ Leave-one-out cross validation predictions
```{r}
# Extract predictions/ Leave-one-out cross validation predictions
test_1r <- residuals(test_1, cross.validation=T)
test_1r.df <- getSSNdata.frame(test_1r)
```

generate a Torgegram of fitted model and save
```{r}
# Torgegram of fitted model residuals
test_1t <- Torgegram(test_1r,"_resid.crossv_",nlag=20)
jpeg("data/ICPRB5/model_torgegram_full.jpg")
plot(test_1t, main= "Model1 Residuals Torgegram") 
dev.off()

jpeg("data/ICPRB5/model_1_flow_connected.jpg")
plot.Torgegram(test_1t, sp.relationship = c("fc"), xlab = "Stream Distance (meter)")
dev.off()

jpeg("data/ICPRB5/model_1_flow_unconnected.jpg")
plot.Torgegram(test_1t, sp.relationship = c("fu"), xlab = "Stream Distance (meter)")
dev.off()
```

```{r}
#Root mean squared error (RMSE) of cross-validated predictions
sqrt(mean((test_1r.df[,"_CrossValPred_"]-test_1r.df$obsval)^2))
# 0.969

#RMSE of fixed effects only
sqrt(mean((test_1r.df[,"_fit_"]-test_1r.df$obsval)^2))
# 1.935

# Null RMSE
sqrt(mean((test_1r.df$obsval-mean(test_1r.df$obsval))^2))
# 2.996

#Pseudo-r2 of cross-validated predictions. 
cor(test_1r.df$obsval,test_1r.df[,"_CrossValPred_"])^2
# 0.895
```

Get parameter estimates, back-transform, and save estimates as model_1_estimates

```{r}
test_1e <- summary(test_1)$fixed.effects.estimates

m1_backtrans <- test_1e[-c(0,10),2:3]/(2*sapply(continuous[,c(1:7,9:11)],sd))

esttable <- cbind(test_1e[,1],rbind(test_1e[1,2:3],m1_backtrans[1:15,],test_1e[10,2:3]), test_1e[,2:5])

write.csv(esttable,"data/ICPRB5/model_1_estimates.csv")

```

### Predictions ###

sample code recommends Data can be split using the splitPredictions if the data has multiple prediction point files in .ssn folder. We only have preds, and a managable dataset size. Below code has been commmented out.
```{r}
# library(SSN)
# test_1$ssn.object <- splitPredictions(test_1$ssn.object, "preds-1",chu
# nksof=10000)
# # splitPredictions
# print(test_1$ssn.object)

```


Running predictions generates an error:

Error in `[.data.frame`(datap, , mod.names[i]) : 
  undefined columns selected
  
A quick internet search shows that this error occurs when you attempt to subset data but leave out a comma, which doesn't apply to anything that is being explicitely done directly by our code here. Below code has been commented out.
```{r}
# #make a prediction
test1p1 <- predict(test_1,predpointsID = "preds")

# # Extract prediction data frames
pred1df <- getSSNdata.frame(test1p1,"preds")
```

Porecess of reassembling data will look something like this. This has been commented out but left in for reference.
```{r}
# Reassemble the pieces into one batch.
#not required since wasn't split

# allpreds <- rbind(pred1df[,c("OBSPREDID","STREAM_AUG","STREAM_AUG.predSE")],pred2df[,c("OBSPREDID","STREAM_AUG","STREAM_AUG.predSE")],pred3df[,c("OBSPREDID","STREAM_AUG","STREAM_AUG.predSE")],pred4df[,c("OBSPREDID","STREAM_AUG","STREAM_AUG.predSE")],pred5df[,c("OBSPREDID","STREAM_AUG","STREAM_AUG.predSE")],pred6df[,c("OBSPREDID","STREAM_AUG","STREAM_AUG.predSE")],pred7df[,c("OBSPREDID","STREAM_AUG","STREAM_AUG.predSE")])
# colnames(allpreds) <- c("OBSPREDID","predtemp","predtempse")
```

Export prediction dataset as a csv (good for general use) and dbf (good for GIS) Commented out as there are currently no predictions to save.
```{r}
library(foreign)

write.csv(pred1df,"data/ICPRB5/model_1_predictions.csv",row.names=F)
write.dbf(pred1df,"data/ICPRB5/model_1_predictions.dbf")

```

Compare predicted and observed at fitting sites, and export. Commented out, no predictions
```{r}
predobs <- data.frame(test_1r.df$OBSPREDID,test_1r.df[,"_CrossValPred_"],test_1r.df$obsval)
colnames(predobs) <- c("obspredid","predicted","observed")
write.csv(predobs,"data/ICPRB5/model_1_prediction_observations.csv",row.names=F)

test_obs <- test_1r.df$OBSPREDID
```
